{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbfb7b4-743b-41fb-90d3-3b52c7db55ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53abc554-bca6-4b11-9b23-899db0b8a483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1fc3747-086e-4db1-ad9a-f95af3cb9572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting blind test dataset generation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_586154/474382294.py:62: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  samples_by_day = df.groupby('day').apply(lambda x: list(x.index)).to_dict()\n",
      "/tmp/ipykernel_586154/474382294.py:62: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  samples_by_day = df.groupby('day').apply(lambda x: list(x.index)).to_dict()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded and filtered 84190 records (789 Positive, 83401 Negative).\n",
      "\n",
      "üîç Sampling 25 Positive and 25 Negative events...\n",
      "Total samples for blind test: 50\n",
      "\n",
      "üîä Generating anonymized audio clips and spectrograms...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing events:   0%|                                                                                                                                                                    | 0/50 [00:00<?, ?it/s]/home/operator0/anaconda3/envs/HydrophoneAnalysis/lib/python3.13/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (1025) may be set too low.\n",
      "  warnings.warn(\n",
      "Processing events: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [02:01<00:00,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Success! Blind test dataset generated.\n",
      "  - Data folder: /run/user/1000/gvfs/smb-share:server=sl-nas.local,share=shared_all/_AZORES_NUUK/Natacha_Group/anomaly_files/Anomalies_Out/blind_test_data\n",
      "  - Sheet for expert: /run/user/1000/gvfs/smb-share:server=sl-nas.local,share=shared_all/_AZORES_NUUK/Natacha_Group/anomaly_files/Anomalies_Out/blind_test_sheet.csv\n",
      "  - Answer key: /run/user/1000/gvfs/smb-share:server=sl-nas.local,share=shared_all/_AZORES_NUUK/Natacha_Group/anomaly_files/Anomalies_Out/answer_key.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# This script was written with the assistance of an AI model.\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import pathlib\n",
    "import torchaudio\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Blind Test Configuration ---\n",
    "\n",
    "# 1. Path to the original 5-minute source audio files.\n",
    "SOURCE_AUDIO_FOLDER = pathlib.Path(\"/run/user/1000/gvfs/smb-share:server=sl-nas.local,share=geomatics/LEG9_S20250708_PSTATSRAADLEHMKUHL/ACOUSTIC/HYDROPHONES\")\n",
    "\n",
    "# 2. Path to the output folder from your main analysis script (where logs are).\n",
    "BASE_OUTPUT_PATH = pathlib.Path(\"/run/user/1000/gvfs/smb-share:server=sl-nas.local,share=shared_all/_AZORES_NUUK/Natacha_Group/anomaly_files/Anomalies_Out/anomalies_output_refactored_filtered_new_instrument_detection\")\n",
    "\n",
    "# 3. Total number of samples to draw for each category from the ENTIRE dataset.\n",
    "#    The script will try to spread these samples across as many days as possible.\n",
    "TOTAL_POSITIVE_SAMPLES = 25  # How many \"High Quality\" samples to select in total.\n",
    "TOTAL_NEGATIVE_SAMPLES = 25  # How many \"Discarded\" samples to select in total.\n",
    "\n",
    "# 4. Settings for the generated files.\n",
    "CLIP_DURATION_SECONDS = 20.0 # Duration for all generated clips.\n",
    "BLIND_TEST_FOLDER = \"blind_test_data\" # Subfolder for all generated files.\n",
    "BLIND_SHEET_FILENAME = \"blind_test_sheet.csv\" # The sheet for the expert to fill out.\n",
    "ANSWER_KEY_FILENAME = \"answer_key.csv\" # The sheet with the true labels and source info.\n",
    "\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def get_loudness_threshold(output_path):\n",
    "    \"\"\"Determines the loudness threshold based on folder existence.\"\"\"\n",
    "    return 2.5 if (output_path / \"high_quality_clips\").exists() else float('inf')\n",
    "\n",
    "def categorize_for_blind_test(row, hq_threshold):\n",
    "    \"\"\"Categorizes anomalies into 'Positive', 'Negative', or 'Ignore' for sampling.\"\"\"\n",
    "    status, reason = row['status'], row['reason']\n",
    "    if status == 'KEPT':\n",
    "        try:\n",
    "            loudness_ratio = float(str(row['details']).split('=')[-1])\n",
    "            return 'Positive' if loudness_ratio >= hq_threshold else 'Ignore'\n",
    "        except (ValueError, IndexError):\n",
    "            return 'Ignore' # Ignore low volume or unparsable 'KEPT' events\n",
    "    elif status == 'DISCARDED':\n",
    "        return 'Negative'\n",
    "    return 'Ignore'\n",
    "\n",
    "def stratified_sample_total(df, n_total):\n",
    "    \"\"\"\n",
    "    Samples a total of n_total items, ensuring maximum diversity across days.\n",
    "    \"\"\"\n",
    "    if n_total == 0:\n",
    "        return pd.DataFrame()\n",
    "    if n_total >= len(df):\n",
    "        return df.copy()\n",
    "\n",
    "    # Create a list of (day, original_index) tuples for round-robin sampling\n",
    "    samples_by_day = df.groupby('day').apply(lambda x: list(x.index)).to_dict()\n",
    "    day_keys = list(samples_by_day.keys())\n",
    "    \n",
    "    final_indices = []\n",
    "    day_idx = 0\n",
    "    while len(final_indices) < n_total and any(samples_by_day.values()):\n",
    "        current_day = day_keys[day_idx % len(day_keys)]\n",
    "        if samples_by_day[current_day]:\n",
    "            # Pop a sample from this day's list\n",
    "            final_indices.append(samples_by_day[current_day].pop(0))\n",
    "        day_idx += 1\n",
    "        \n",
    "    return df.loc[final_indices].copy()\n",
    "\n",
    "\n",
    "def generate_clip_and_spectrogram(row, source_folder, output_dir, event_id):\n",
    "    \"\"\"\n",
    "    Generates a standardized audio clip and a spectrogram image for a given event.\n",
    "    Returns the basenames of the created files.\n",
    "    \"\"\"\n",
    "    source_audio_path = source_folder / row['file']\n",
    "    if not source_audio_path.exists():\n",
    "        print(f\"‚ö†Ô∏è Source audio not found: {source_audio_path}\")\n",
    "        return None, None\n",
    "\n",
    "    try:\n",
    "        info = torchaudio.info(source_audio_path)\n",
    "        sr = info.sample_rate\n",
    "        ts = float(row['timestamp_s'])\n",
    "        \n",
    "        # Calculate start/end for a centered clip\n",
    "        half_duration_samples = int(CLIP_DURATION_SECONDS / 2 * sr)\n",
    "        center_sample = int(ts * sr)\n",
    "        start_sample = max(0, center_sample - half_duration_samples)\n",
    "        end_sample = min(info.num_frames, center_sample + half_duration_samples)\n",
    "        \n",
    "        waveform, _ = torchaudio.load(source_audio_path, frame_offset=start_sample, num_frames=(end_sample - start_sample))\n",
    "\n",
    "        # Save audio clip\n",
    "        clip_path = output_dir / f\"{event_id}.wav\"\n",
    "        torchaudio.save(clip_path, waveform, sr)\n",
    "        \n",
    "        # Generate and save spectrogram\n",
    "        mel_spectrogram_transform = torchaudio.transforms.MelSpectrogram(sample_rate=sr, n_fft=2048, hop_length=512, n_mels=128)\n",
    "        melspec = mel_spectrogram_transform(waveform)\n",
    "        \n",
    "        # Convert to dB scale for better visualization\n",
    "        melspec_db = torchaudio.transforms.AmplitudeToDB()(melspec)\n",
    "\n",
    "        spec_path = output_dir / f\"{event_id}.png\"\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.imshow(melspec_db.squeeze().numpy(), aspect='auto', origin='lower', cmap='viridis')\n",
    "        plt.axis('off')\n",
    "        plt.savefig(spec_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "        \n",
    "        return clip_path.name, spec_path.name\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to generate files for {event_id} from {row['file']}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Generates a blind test dataset with anonymized files and separate answer key.\"\"\"\n",
    "    print(\"üöÄ Starting blind test dataset generation...\")\n",
    "\n",
    "    # --- 1. Load, Categorize, and Filter ---\n",
    "    LOUDNESS_THRESHOLD = get_loudness_threshold(BASE_OUTPUT_PATH)\n",
    "    log_files = glob.glob(str(BASE_OUTPUT_PATH / \"*_detailed_log.csv\"))\n",
    "    if not log_files:\n",
    "        print(f\"‚ùå Error: No log files found in '{BASE_OUTPUT_PATH}'.\"); return\n",
    "\n",
    "    df = pd.concat((pd.read_csv(f) for f in log_files), ignore_index=True)\n",
    "    df['day'] = df['file'].str.extract(r'_(\\d{8})_')\n",
    "    df['blind_category'] = df.apply(categorize_for_blind_test, axis=1, hq_threshold=LOUDNESS_THRESHOLD)\n",
    "    \n",
    "    # Keep only rows that are clearly positive or negative\n",
    "    df_filtered = df[df['blind_category'].isin(['Positive', 'Negative'])].copy()\n",
    "    print(f\"Loaded and filtered {len(df_filtered)} records ({len(df_filtered[df_filtered['blind_category']=='Positive'])} Positive, {len(df_filtered[df_filtered['blind_category']=='Negative'])} Negative).\")\n",
    "\n",
    "    # --- 2. Perform Stratified Sampling ---\n",
    "    print(f\"\\nüîç Sampling {TOTAL_POSITIVE_SAMPLES} Positive and {TOTAL_NEGATIVE_SAMPLES} Negative events...\")\n",
    "    positive_df = df_filtered[df_filtered['blind_category'] == 'Positive']\n",
    "    negative_df = df_filtered[df_filtered['blind_category'] == 'Negative']\n",
    "\n",
    "    positive_samples = stratified_sample_total(positive_df, TOTAL_POSITIVE_SAMPLES)\n",
    "    negative_samples = stratified_sample_total(negative_df, TOTAL_NEGATIVE_SAMPLES)\n",
    "    \n",
    "    if positive_samples.empty and negative_samples.empty:\n",
    "        print(\"‚ùå Error: No samples were collected. Check your data and sample counts.\"); return\n",
    "\n",
    "    # Combine and shuffle for blindness\n",
    "    final_samples_df = pd.concat([positive_samples, negative_samples]).sample(frac=1).reset_index(drop=True)\n",
    "    print(f\"Total samples for blind test: {len(final_samples_df)}\")\n",
    "\n",
    "    # --- 3. Generate Files and Collect Data for CSVs ---\n",
    "    print(\"\\nüîä Generating anonymized audio clips and spectrograms...\")\n",
    "    output_data_dir = BASE_OUTPUT_PATH.parent / BLIND_TEST_FOLDER\n",
    "    output_data_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    blind_sheet_data = []\n",
    "    answer_key_data = []\n",
    "\n",
    "    for _, row in tqdm(final_samples_df.iterrows(), total=len(final_samples_df), desc=\"Processing events\"):\n",
    "        event_id = uuid.uuid4().hex[:10] # Short, unique ID\n",
    "        \n",
    "        audio_file, spec_file = generate_clip_and_spectrogram(row, SOURCE_AUDIO_FOLDER, output_data_dir, event_id)\n",
    "        \n",
    "        if audio_file and spec_file:\n",
    "            # Data for the expert's sheet\n",
    "            blind_sheet_data.append({'event_id': event_id, 'label (INPUT)': ''})\n",
    "            \n",
    "            # Data for the answer key\n",
    "            answer_key_data.append({\n",
    "                'event_id': event_id,\n",
    "                'audio_file': audio_file,\n",
    "                'spectrogram_file': spec_file,\n",
    "                'true_category': row['blind_category'],\n",
    "                'original_file': row['file'],\n",
    "                'timestamp_s': row['timestamp_s'],\n",
    "                'day': row['day'],\n",
    "                'original_status': row['status'],\n",
    "                'original_reason': row['reason'],\n",
    "                'original_details': row['details']\n",
    "            })\n",
    "\n",
    "    # --- 4. Create and Save Final CSVs ---\n",
    "    if not blind_sheet_data:\n",
    "        print(\"‚ùå Error: Failed to generate any valid data. Halting.\"); return\n",
    "\n",
    "    # Create the blind sheet for the expert\n",
    "    blind_df = pd.DataFrame(blind_sheet_data)\n",
    "    blind_sheet_path = BASE_OUTPUT_PATH.parent / BLIND_SHEET_FILENAME\n",
    "    blind_df.to_csv(blind_sheet_path, index=False)\n",
    "    \n",
    "    # Create the answer key for validation\n",
    "    key_df = pd.DataFrame(answer_key_data)\n",
    "    key_sheet_path = BASE_OUTPUT_PATH.parent / ANSWER_KEY_FILENAME\n",
    "    key_df.to_csv(key_sheet_path, index=False)\n",
    "\n",
    "    print(\"\\n‚úÖ Success! Blind test dataset generated.\")\n",
    "    print(f\"  - Data folder: {output_data_dir.resolve()}\")\n",
    "    print(f\"  - Sheet for expert: {blind_sheet_path.resolve()}\")\n",
    "    print(f\"  - Answer key: {key_sheet_path.resolve()}\")\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8e89b3-3e03-4ab4-9d28-7ff35d51f137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17df1e4-e063-4178-95e8-8a72b1c941c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47a83d8-e82a-44ad-8454-2e0007602260",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
